# The proposal
<!--
This is where the proposal should be outlined. 
-->

<!-- ## Overview -->
<!--
At a high-level address what your proposal is and how it will address the problem identified. Highlight any benefits to the R Community that follow from solving the problem. This should be your most compelling section.
-->

<!-- ## Detail -->
<!--
Go into more detail about the specifics of the project and it delivers against the problem.

Depending on project type the detail section should include:

 - [ ] Minimum Viable Product
 - [ ] Architecture
 - [ ] Assumptions
-->

I propose a framework in which we provide a single user interface to many different research data repositories. My approach is like that of dplyr; whereas dplyr “verbs” work identically across many backends (e.g., spreadsheet, SQL database), this project will simplify data deposition under a common set of commands. This model of decoupling the interface from the backend has proven successful, but has not yet been applied to the important task of researchers sharing data.

There are thousands of different data repositories, with many aspects that differ among them (e.g., disciplinary scope, openness, data submission format, authentication methods). While only a handful of repositories may be relevant to any individual researcher, the fact that each one likely implements totally different interfaces and protocols for depositing/updating data creates significant barriers for end users. We aim to simplify all of that complexity to make depositing data much easier. 

As there are so many data research repositories, it would not be feasible for a few developers to maintain extensions for so many different sources and verify they work. Instead, I will design a package that implements a modular/plugin system so that users can contribute their own plugins to extend functionality to other repositories. Detailed vignettes will be written to document this process.

One of the first steps will be to complete research on data repositories using the Registry of Research Data Repositories (https://www.re3data.org/).  This will allow us to quickly get familiar with the diversity of technical details behind data repositories. I will narrow the set down to two repositories that are widely used so we can provide the largest immediate payoff upon project completion. In addition, the focus on two widely used repositories will make the complexity manageable while still providing enough variety so that we’ll cover a large number of users.

My significant experience in working with web services will help make interactions with data repositories as smooth as possible. I created and maintain packages for major aspects of working with web services in R: crul, an HTTP client (similar to httr); webmockr, for mocking HTTP requests; and vcr, for caching HTTP requests in unit tests.

Many of the pieces for interacting with repositories are already implemented by rOpenSci staff or community members. For example, Karthik Ram and I maintain the R package rdryad for interacting with Dryad, one of the larger general purpose data repositories, to which we’ve recently added the ability to upload datasets. Another major data repository is the Open Science Framework (OSF) - an rOpenSci community member Aaron Wolen maintains the package osfr for OSF (which also has data upload functionality). Using these existing packages as dependencies, I can more quickly build the plumbing for interacting with data repositories.

The package structure will have the following components (see figure below): authenticate, prepare data and metadata, submit data, fetch data, and browse data. Authentication will entail abstracting a lot of complexity, making the process simple for the user. Next we’ll help users prepare their data and metadata. This step will vary based on the data repository; in some cases this will be the last step before the user has to submit data manually on a website; in other cases we can proceed to submitting data. Data submission will entail typically a POST HTTP request with metadata and data, returning the status of the submission attempt. After submitting data, I’ll encourage users to fetch their data to make sure that the data submission worked. Last, if the data repository has a landing page for the uploaded dataset within a short period, we can bring the user to that page to make sure everything is correct.

The following is an example of what a workflow will look like using pseudo-code. 

Authenticate:

```r
library(deposits)
Sys.setenv(DRYAD_TOKEN = ”some-token”)
deposits::auth(repo = “dryad”)
```

Prepare metadata and data:

```r
x <- readr::read_csv(“users-data.csv”)
my_metadata <- deposits::prep_metadata(x)
my_data <- deposits::prep_data(x)
```

Submit metadata and data:

```r
out <- deposits::submit(data = my_data, metadata = my_metadata)
```

Fetch and browse data:

```r
out$id
#> “dataset-identifier”
deposits::fetch(x$id)
deposits::browse(x$id)
```

I anticipate using the following packages to support the proposed components:
- Authentication: httr, crul
- Prepare data: vroom, data.table
- Prepare metadata: various, including: xml2, jsonlite, rdflib
- Submit in R / Fetch data / Browse data: httr, crul

<!-- img -->

It may make sense after some work is done to break off parts of the package into additional package(s). The R package devtools has shown us that placing too many disparate tasks in a single package can be better accomplished by separating them. 


### Project plan

#### Start-up phase

We’ll start with research on data repositories. This will entail using the Registry of Research Data Repositories, including communication with repository managers to clarify any details which are not clear or not documented. In addition, we’ll identify users of each repository to help us test the package. Details on data repository research:

- Select two data repositories to focus on. Build out documentation on how to add additional data repositories so that most of the work of extending to new repositories is done by community members
- Find the most common set of actions we can perform with data repositories
- Find data repositories that do not support programmatic data upload - for these we can help users prepare data for browser based submission
- Does each data repository use any standard or vocabulary we can use to help prepare/validate data for users?

#### Technical delivery

- Design plugin system to allow for anyone to extend the package for any additional data repositories
- Design public API (user facing functions) with function names that convey meaning following the usethis package model.
- Implement authentication following best practices for security, including support for (as needed):
  - user/password
  - API token
  - OAuth
- Implement data fetch methods first - as this is easier than creating data and users will want it anyway - this will help us get familiar with each data repository
- Implement metadata and data preparation methods
- Implement data upload methods
- Documentation: write detailed documentation, including many vignettes, on a pkgdown site
- User testing: we’ll test the package ourselves throughout the development process; this step is to get users to test the package to smooth out any user interface problems


### Dissemination

- License will be MIT
- Blog posts, ropensci community call, conf. talk, R Consortium blog post
- Submission to CRAN
- The code will be developed in the open in the rOpenSci GitHub organisation. Discussion of the  deposit project will happen in public issues of the repository. The license will be MIT.
- We may submit to rOpenSci software review to further refine the package
